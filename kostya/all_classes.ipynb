{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataset_creator import DatasetCreator\n",
    "from preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creator = DatasetCreator(created=True)\n",
    "pp = Preprocessor(created=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for BatchGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Que and pro feature dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49722, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_data = pp.qa_data.merge(pp.stud_data, on='students_id')\n",
    "qa_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_content = qa_data[[\n",
    "    'students_state',\n",
    "    'students_location',\n",
    "    \n",
    "    'questions_body_length',\n",
    "    \n",
    "#     'students_average_question_body_length',\n",
    "#     'students_average_answer_body_length',\n",
    "]]\n",
    "\n",
    "que_time = qa_data[[\n",
    "#     'students_questions_asked',\n",
    "#     'students_average_question_age',\n",
    "    \n",
    "    'students_date_joined_time',\n",
    "    'students_date_joined_doy_sin',\n",
    "    'students_date_joined_doy_cos',\n",
    "    \n",
    "    'questions_date_added_time',\n",
    "    'questions_date_added_doy_sin',\n",
    "    'questions_date_added_doy_cos',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "que = pp.qa_data.questions_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_content_dict = {que.loc[i]: que_content.loc[i].values for i in range(que.size)}\n",
    "que_time_dict = {que.loc[i]: que_time.loc[i].values for i in range(que.size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_content = pp.prof_data[[\n",
    "    'professionals_state',\n",
    "    'professionals_location',\n",
    "    'professionals_industry',\n",
    "    \n",
    "#     'professionals_average_question_body_length',\n",
    "#     'professionals_average_answer_body_length',\n",
    "]]\n",
    "\n",
    "pro_time = pp.prof_data[[\n",
    "#     'professionals_questions_answered',\n",
    "#     'professionals_average_question_age',\n",
    "#     'professionals_email_activated',\n",
    "    \n",
    "    'professionals_date_joined_time',\n",
    "    'professionals_date_joined_doy_sin',\n",
    "    'professionals_date_joined_doy_cos',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = pp.prof_data.professionals_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_content_dict = {pro.loc[i]: pro_content.loc[i].values for i in range(pro.size)}\n",
    "pro_time_dict = {pro.loc[i]: pro_time.loc[i].values for i in range(pro.size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('que_content_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(que_content_dict, f)\n",
    "with open('que_time_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(que_time_dict, f)\n",
    "with open('pro_content_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(pro_content_dict, f)\n",
    "with open('pro_time_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(pro_time_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-related feature dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers_id</th>\n",
       "      <th>answers_date_added_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>-0.699372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>334f6735d31e45589e43da5ae7056e50</td>\n",
       "      <td>0.747848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5d66281cc314675b95ddbb799b75473</td>\n",
       "      <td>0.747848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e5c0da2a29ff414fa76b9da6e86337fc</td>\n",
       "      <td>-0.560503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f3519ab99a1a4a13a8a9ecb814287d2a</td>\n",
       "      <td>-0.500911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         answers_id  answers_date_added_time\n",
       "0  4e5f01128cae4f6d8fd697cec5dca60c                -0.699372\n",
       "1  334f6735d31e45589e43da5ae7056e50                 0.747848\n",
       "2  e5d66281cc314675b95ddbb799b75473                 0.747848\n",
       "3  e5c0da2a29ff414fa76b9da6e86337fc                -0.560503\n",
       "4  f3519ab99a1a4a13a8a9ecb814287d2a                -0.500911"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_prev_answer_date = pp.qa_data[['answers_id', 'professionals_prev_answer_date_time']]\n",
    "ans_date_added = pp.qa_data[['answers_id', 'answers_date_added_time']]\n",
    "que_date_added = pp.qa_data[['questions_id', 'questions_date_added_time']]\n",
    "ans_date_added.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_date_added_dict = {ans:date for ans, date in ans_date_added.values}\n",
    "que_date_added_dict = {que:date for que, date in que_date_added.values}\n",
    "ans_prev_answer_date_dict = {ans:date for ans, date in ans_prev_answer_date.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change last_answer_date feature for incorrect professionals\n",
    "pro_answer_dates_dict = {pro:df_slice.professionals_prev_answer_date_time.sort_values().values.tolist()\n",
    "                         for pro, df_slice in pp.qa_data.groupby('professionals_id')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_last_anwer_date_dict = {pro:df_slice.answers_date_added_time.max()\n",
    "                            for pro, df_slice in pp.qa_data.groupby('professionals_id')}\n",
    "\n",
    "# Load preprocessors here\n",
    "import pickle\n",
    "with open('preprocessors.pickle', 'rb') as f:\n",
    "    preproc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pro, last_answer_date in pro_last_anwer_date_dict.items():\n",
    "    last_answer_date = preproc['answers_date_added_time'].inverse_transform([[last_answer_date]])\n",
    "    pro_last_anwer_date_dict[pro] = preproc['professionals_last_answer_date_time'].transform(last_answer_date)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pro in pro_answer_dates_dict.keys():\n",
    "    pro_answer_dates_dict[pro].append(pro_last_anwer_date_dict[pro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pro_answer_dates_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(pro_answer_dates_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_reg_dates = pp.prof_data[['professionals_id', 'professionals_date_joined_time']]\n",
    "pro_reg_dates = pro_reg_dates.sort_values(by='professionals_date_joined_time')\n",
    "pro_reg_dates['professionals_date_joined_time'] = pro_reg_dates['professionals_date_joined_time'].apply(\n",
    "        lambda x: preproc['professionals_date_joined_time'].inverse_transform([[x]])[0][0])\n",
    "pro_list = pro_reg_dates['professionals_id'].values.tolist()\n",
    "pro_reg_date_list = pro_reg_dates['professionals_date_joined_time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ans_date_added_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(ans_date_added_dict, f)\n",
    "with open('que_date_added_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(que_date_added_dict, f)\n",
    "with open('ans_prev_answer_date_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(ans_prev_answer_date_dict, f)\n",
    "with open('pro_list.pickle', 'wb') as f:\n",
    "    pickle.dump(pro_list, f)\n",
    "with open('pro_reg_date_list.pickle', 'wb') as f:\n",
    "    pickle.dump(pro_reg_date_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessors\n",
    "import pickle\n",
    "with open('preprocessors.pickle', 'rb') as f:\n",
    "    preproc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.data_data['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans_list = pp.qa_data.answers_id.values\n",
    "ans_dates = pp.qa_data.answers_date_added_time.apply(\n",
    "    lambda x: preproc['answers_date_added_time'].inverse_transform([[x]])[0][0]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44502,), (5220,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = 2018.67\n",
    "train_ans_list, test_ans_list = ans_list[ans_dates < date], ans_list[ans_dates >= date]\n",
    "train_ans_list.shape, test_ans_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_ans_list.pickle', 'wb') as f:\n",
    "    pickle.dump(train_ans_list, f)\n",
    "with open('test_ans_list.pickle', 'wb') as f:\n",
    "    pickle.dump(test_ans_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pro_answer_dates_dict.pickle', 'rb') as f:\n",
    "    pro_answer_dates_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_date_pro_list = [(answer_date, pro)\n",
    "                        for pro, answer_dates in pro_answer_dates_dict.items()\n",
    "                        for answer_date in answer_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59737"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_date_pro_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_times = pd.DataFrame.from_records(answer_date_pro_list, columns=['prev_answer_date_time', 'professionals_id'])\n",
    "answer_times.sort_values(by='prev_answer_date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_answer_date_time</th>\n",
       "      <th>professionals_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>-4.133939</td>\n",
       "      <td>0c673e046d824ec0ad0ebe012a0673e4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35302</th>\n",
       "      <td>-4.087291</td>\n",
       "      <td>977428d851b24183b223be0eb8619a8c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47892</th>\n",
       "      <td>-4.018243</td>\n",
       "      <td>c9bfa93898594cbbace436deca644c64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>-3.989516</td>\n",
       "      <td>0c9a2748560541be9fe2df0d7be88282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47577</th>\n",
       "      <td>-3.989516</td>\n",
       "      <td>c79d4e4fd9af4ab7a7e6b6f433128476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prev_answer_date_time                  professionals_id\n",
       "2928               -4.133939  0c673e046d824ec0ad0ebe012a0673e4\n",
       "35302              -4.087291  977428d851b24183b223be0eb8619a8c\n",
       "47892              -4.018243  c9bfa93898594cbbace436deca644c64\n",
       "2992               -3.989516  0c9a2748560541be9fe2df0d7be88282\n",
       "47577              -3.989516  c79d4e4fd9af4ab7a7e6b6f433128476"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26740"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.searchsorted(answer_times.prev_answer_date_time.values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_times.to_pickle('answer_times.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_answer_date_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionals_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66a6d2d213da44fbbf6e9407df46be73</th>\n",
       "      <td>-3.914846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66a6d2d213da44fbbf6e9407df46be73</th>\n",
       "      <td>-3.914846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  prev_answer_date_time\n",
       "professionals_id                                       \n",
       "66a6d2d213da44fbbf6e9407df46be73              -3.914846\n",
       "66a6d2d213da44fbbf6e9407df46be73              -3.914846"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_times.set_index('professionals_id').loc['66a6d2d213da44fbbf6e9407df46be73']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings for questions from doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doc2vec import train, save\n",
    "import re\n",
    "\n",
    "from utils import TextProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What  is  a  maths  teacher?   what  is  a  maths  teacher  useful? #college #professor #lecture'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.questions.loc[0, 'questions_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a maths teacher? what is a maths teacher useful? college professor lecture'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.questions.questions_body = (pp.questions.questions_body\n",
    "    .apply(lambda x: re.sub(r'(<[^>]*[/]?>|[\\r]?\\n)', ' ', str(x)))\n",
    "    .apply(lambda x: re.sub(r' +', ' ', x).strip())\n",
    "    .apply(lambda x: x.replace('#', '')))\n",
    "pp.questions.questions_body.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Teacher career question'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.questions.questions_title = (pp.questions.questions_title\n",
    "    .apply(lambda x: re.sub(r'(<[^>]*[/]?>|[\\r]?\\n)', ' ', str(x)))\n",
    "    .apply(lambda x: re.sub(r' +', ' ', x).strip())\n",
    "    .apply(lambda x: x.replace('#', '')))\n",
    "pp.questions.questions_title.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextProcessor()\n",
    "for column in ['questions_title', 'questions_body']:\n",
    "    pp.questions[column] = pp.questions[column].apply(tp.process, allow_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan go abroad first job teach job seriou career idea know job would work stay home instead assum stay leav makeba huge differ care unless find someth first job think way go abroad seen good bad know side respect employ willl side work abroad employ oversea'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.questions.questions_body.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_embs = train(pp.questions, 'questions_id', ['questions_title', 'questions_body'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(questions_embs, 'questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_users = pp.tag_users\n",
    "pro = pp.professionals\n",
    "stu = pp.students\n",
    "tags = pp.tags\n",
    "\n",
    "pro_tags = pro.merge(tag_users, left_on='professionals_id', right_on='tag_users_user_id').merge(tags, left_on = 'tag_users_tag_id', right_on='tags_tag_id')\n",
    "pro_tags = pro_tags[['professionals_id', 'tags_tag_name']].groupby(by='professionals_id', as_index = False).aggregate(lambda x: ' '.join(x))\n",
    "pro_tags = {row['professionals_id']: row['tags_tag_name'].split() for _, row in pro_tags.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pros_with_tags = list(pro_tags.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10015"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.prof_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9300"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'professionals_id': pros_with_tags}).merge(pp.prof_data[['professionals_id']], on='professionals_id').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_tags = stu.merge(tag_users, left_on='students_id', right_on='tag_users_user_id').merge(tags, left_on = 'tag_users_tag_id', right_on='tags_tag_id')\n",
    "stu_tags = stu_tags[['students_id', 'tags_tag_name']].groupby(by='students_id', as_index = False).aggregate(lambda x: ' '.join(x))\n",
    "stu_tags = {row['students_id']: row['tags_tag_name'].split() for _, row in stu_tags.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stu_with_tags = list(stu_tags.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11985"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.stud_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3673"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'students_id': stu_with_tags}).merge(pp.stud_data[['students_id']], on='students_id').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchGenerator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from scipy.stats import cauchy\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import TextProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Generates batch of data in train and test modes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pos_size, neg_size, mode='train', data_path='../../data/'):\n",
    "        self.pos_size = pos_size\n",
    "        self.neg_size = neg_size\n",
    "        \n",
    "        que = pd.read_csv(data_path + 'questions.csv')\n",
    "        tag_que = pd.read_csv(data_path + 'tag_questions.csv')\n",
    "        tags = pd.read_csv(data_path + 'tags.csv')\n",
    "        pro = pd.read_csv(data_path + 'professionals.csv')\n",
    "        stu = pd.read_csv(data_path + 'students.csv')\n",
    "        ans = pd.read_csv(data_path + 'answers.csv')\n",
    "        tag_users = pd.read_csv(data_path + 'tag_users.csv')\n",
    "        \n",
    "        self.tp = TextProcessor()\n",
    "        pro['professionals_industry'] = pro['professionals_industry'].apply(self.tp.process)\n",
    "        tags['tags_tag_name'] = tags['tags_tag_name'].apply(lambda x: self.tp.process(x, allow_stopwords=True))\n",
    "        \n",
    "        self.pro_ind = {row['professionals_id']: row['professionals_industry'] for i, row in pro.iterrows()}\n",
    "        \n",
    "        que_tags = que.merge(tag_que, left_on = 'questions_id', right_on = 'tag_questions_question_id').merge(tags, left_on = 'tag_questions_tag_id', right_on = 'tags_tag_id')\n",
    "        que_tags = que_tags[['questions_id', 'tags_tag_name']].groupby(by = 'questions_id', as_index = False).aggregate(lambda x: ' '.join(x))\n",
    "        self.que_tags = {row['questions_id']: row['tags_tag_name'].split() for _, row in que_tags.iterrows()}\n",
    "        \n",
    "        pro_tags = pro.merge(tag_users, left_on='professionals_id', right_on='tag_users_user_id').merge(tags, left_on = 'tag_users_tag_id', right_on='tags_tag_id')\n",
    "        pro_tags = pro_tags[['professionals_id', 'tags_tag_name']].groupby(by='professionals_id', as_index = False).aggregate(lambda x: ' '.join(x))\n",
    "        self.pro_tags = {row['professionals_id']: row['tags_tag_name'].split() for _, row in pro_tags.iterrows()}\n",
    "        \n",
    "        stu_tags = stu.merge(tag_users, left_on='students_id', right_on='tag_users_user_id').merge(tags, left_on = 'tag_users_tag_id', right_on='tags_tag_id')\n",
    "        stu_tags = stu_tags[['students_id', 'tags_tag_name']].groupby(by='students_id', as_index = False).aggregate(lambda x: ' '.join(x))\n",
    "        self.stu_tags = {row['students_id']: row['tags_tag_name'].split() for _, row in stu_tags.iterrows()}\n",
    "        \n",
    "        ans_que = ans.merge(que, left_on = 'answers_question_id', right_on = 'questions_id')\n",
    "        ans_que_pro = ans_que.merge(pro, left_on = 'answers_author_id', right_on = 'professionals_id')\n",
    "        ans_que_pro = ans_que_pro.merge(stu, left_on = 'questions_author_id', right_on = 'students_id')\n",
    "        \n",
    "        # Add a dictionary mapping answer to (question, professional) pair\n",
    "        self.ans_que_pro_dict = {row['answers_id']:(row['questions_id'], row['professionals_id'])\n",
    "                                 for _, row in ans_que_pro.iterrows()}\n",
    "        \n",
    "        self.que_stu_dict = {row['questions_id']: row['students_id'] for _, row in ans_que_pro.iterrows()}\n",
    "        self.que_pro_set = {(row['questions_id'], row['professionals_id']) for _, row in ans_que_pro.iterrows()}\n",
    "        \n",
    "        with open('tags_embs.pkl', 'rb') as f:\n",
    "            self.tag_emb = pickle.load(f)\n",
    "        with open('industries_embs.pkl', 'rb') as f:\n",
    "            self.ind_emb = pickle.load(f)\n",
    "        \n",
    "        # Load que and pro content and time related features\n",
    "        with open('que_content_dict.pickle', 'rb') as f:\n",
    "            self.que_content_dict = pickle.load(f)\n",
    "        with open('que_time_dict.pickle', 'rb') as f:\n",
    "            self.que_time_dict = pickle.load(f)\n",
    "        with open('pro_content_dict.pickle', 'rb') as f:\n",
    "            self.pro_content_dict = pickle.load(f)\n",
    "        with open('pro_time_dict.pickle', 'rb') as f:\n",
    "            self.pro_time_dict = pickle.load(f)\n",
    "        \n",
    "        # Load time related dicts and lists\n",
    "        with open('pro_answer_dates_dict.pickle', 'rb') as f:\n",
    "            self.pro_answer_dates_dict = pickle.load(f)\n",
    "        with open('ans_date_added_dict.pickle', 'rb') as f:\n",
    "            self.ans_date_added_dict = pickle.load(f)\n",
    "        with open('que_date_added_dict.pickle', 'rb') as f:\n",
    "            self.que_date_added_dict = pickle.load(f)\n",
    "        with open('ans_prev_answer_date_dict.pickle', 'rb') as f:\n",
    "            self.ans_prev_answer_date_dict = pickle.load(f)\n",
    "        with open('pro_list.pickle', 'rb') as f:\n",
    "            self.pro_list = pickle.load(f)\n",
    "        with open('pro_reg_date_list.pickle', 'rb') as f:\n",
    "            self.pro_reg_date_list = pickle.load(f)\n",
    "        \n",
    "        # Load preprocessors\n",
    "        with open('preprocessors.pickle', 'rb') as f:\n",
    "            self.preproc = pickle.load(f)\n",
    "        \n",
    "        # Load answer list depending on the mode\n",
    "        if mode == 'train':\n",
    "            with open('train_ans_list.pickle', 'rb') as f:\n",
    "                self.ans_list = pickle.load(f)\n",
    "        elif mode == 'test':\n",
    "            with open('test_ans_list.pickle', 'rb') as f:\n",
    "                self.ans_list = pickle.load(f)\n",
    "        \n",
    "        # Load questions embeddings\n",
    "        with open('questions_embs.pkl', 'rb') as f:\n",
    "            self.que_emb = pickle.load(f)\n",
    "        \n",
    "#         print(\"Begin que computing!\")\n",
    "#         que_emb_dict = {que:self.convert_que(que) for que in ans_que_pro.questions_id.unique()}\n",
    "        \n",
    "#         print(\"Begin pro computing!\")\n",
    "#         pro_emb_dict = {pro:self.convert_pro(pro) for pro in ans_que_pro.professionals_id.unique()}\n",
    "        \n",
    "#         with open('que_emb_dict.pickle', 'wb') as f:\n",
    "#             pickle.dump(que_emb_dict, f)\n",
    "#         with open('pro_emb_dict.pickle', 'wb') as f:\n",
    "#             pickle.dump(pro_emb_dict, f)\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ans_list) // self.pos_size\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pos_pairs = []\n",
    "        neg_pairs = []\n",
    "        \n",
    "        pos_prev_dates = []\n",
    "        neg_prev_dates = []\n",
    "        \n",
    "        pos_cur_times = []\n",
    "        neg_cur_times = []\n",
    "        \n",
    "        pos_que_content, pos_que_time, pos_pro_content, pos_pro_time = [], [], [], []\n",
    "        neg_que_content, neg_que_time, neg_pro_content, neg_pro_time = [], [], [], []\n",
    "        \n",
    "        pos_ans = self.ans_list[self.pos_size * index: self.pos_size * (index + 1)]\n",
    "        for ans in pos_ans:\n",
    "            # Add que and pro features and dates to appropriate lists\n",
    "            que, pro = self.ans_que_pro_dict[ans]\n",
    "            pos_pairs.append((que, pro))\n",
    "            \n",
    "            pos_que_content.append(self.que_content_dict[que])\n",
    "            pos_que_time.append(self.que_time_dict[que])\n",
    "            \n",
    "            pos_pro_content.append(self.pro_content_dict[pro])\n",
    "            pos_pro_time.append(self.pro_time_dict[pro])\n",
    "            \n",
    "            pos_prev_dates.append(self.ans_prev_answer_date_dict[ans])\n",
    "            pos_cur_times.append(self.ans_date_added_dict[ans])\n",
    "        \n",
    "        for i in range(self.neg_size):\n",
    "            ans = random.choice(self.ans_list)\n",
    "            que, _ = self.ans_que_pro_dict[ans]\n",
    "            \n",
    "            # Current time is realization of absolute value of Cauchy random variable\n",
    "            cur_time = np.abs(cauchy.rvs(loc=0, scale=12.5))\n",
    "            \n",
    "            # Inverse transform current time\n",
    "            cur_time = (self.preproc['questions_date_added_time']\n",
    "                        .inverse_transform([[self.que_date_added_dict[que]]])[0][0] + cur_time / 365)\n",
    "            \n",
    "            # Include professionals whos registration date is belove threshold\n",
    "            threshold = np.searchsorted(self.pro_reg_date_list, cur_time)\n",
    "            valid_pros = self.pro_list[:threshold]\n",
    "            \n",
    "            # Transform current time with preprocessor for professionals_prev_answer_date_time\n",
    "            cur_time = self.preproc['professionals_prev_answer_date_time'].transform([[cur_time]])[0][0]\n",
    "            \n",
    "#             #-------------------------------------------------------------------------\n",
    "#             #                          WITH DISTRIBUTION\n",
    "            \n",
    "#             # Sample 50 (or less) pros among valid ones\n",
    "#             sampled_pros = random.sample(valid_pros, min(50, len(valid_pros)))\n",
    "            \n",
    "#             pros = []\n",
    "#             prev_answer_dates = []\n",
    "            \n",
    "#             # Compute previous answer date for every sampled professional\n",
    "#             for pro in sampled_pros:\n",
    "#                 if (que, pro) not in self.que_pro_set:\n",
    "#                     prev_answer_date = self.__negative_que_prev_answer_date(pro, cur_time)\n",
    "                    \n",
    "#                     pros.append(pro)\n",
    "#                     prev_answer_dates.append(prev_answer_date)\n",
    "            \n",
    "#             if len(pros) == 0:\n",
    "#                 continue\n",
    "            \n",
    "#             # Substact prev answer dates from cur_time\n",
    "#             distances = cur_time - np.array(prev_answer_dates)\n",
    "            \n",
    "#             # Apply log1p transformation to 1 / distances and normalize each entry\n",
    "#             distances = np.log1p(1 / distances)\n",
    "#             distances /= distances.sum()\n",
    "            \n",
    "#             # Sample one professional from distribution of distances\n",
    "#             pro = np.random.choice(pros, p=distances)\n",
    "#             #-------------------------------------------------------------------------\n",
    "            \n",
    "            #-------------------------------------------------------------------------\n",
    "            #                         WITHOUT DISTRIBUTION\n",
    "            \n",
    "            pro = random.choice(valid_pros)\n",
    "            while (que, pro) in self.que_pro_set:\n",
    "                pro = random.choice(valid_pros)\n",
    "            #-------------------------------------------------------------------------\n",
    "            \n",
    "            prev_date = self.__negative_que_prev_answer_date(pro, cur_time)\n",
    "            \n",
    "            # Add que and pro features and dates to appropriate lists\n",
    "            neg_pairs.append((que, pro))\n",
    "            \n",
    "            neg_que_content.append(self.que_content_dict[que])\n",
    "            neg_que_time.append(self.que_time_dict[que])\n",
    "            \n",
    "            neg_pro_content.append(self.pro_content_dict[pro])\n",
    "            neg_pro_time.append(self.pro_time_dict[pro])\n",
    "            \n",
    "            neg_prev_dates.append(prev_date)\n",
    "            neg_cur_times.append(cur_time)\n",
    "        \n",
    "        pos_que_embeddings, pos_pro_embeddings = self.__convert(pos_pairs)\n",
    "        neg_que_embeddings, neg_pro_embeddings = self.__convert(neg_pairs)\n",
    "        \n",
    "        pos_que = np.hstack([\n",
    "            np.array(pos_que_content),\n",
    "            pos_que_embeddings,\n",
    "            np.array(pos_que_time),\n",
    "            np.array(pos_cur_times)[:, np.newaxis],\n",
    "        ])\n",
    "        neg_que = np.hstack([\n",
    "            np.array(neg_que_content),\n",
    "            neg_que_embeddings,\n",
    "            np.array(neg_que_time),\n",
    "            np.array(neg_cur_times)[:, np.newaxis],\n",
    "        ])\n",
    "        \n",
    "        pos_pro = np.hstack([\n",
    "            np.array(pos_pro_content),\n",
    "            pos_pro_embeddings,\n",
    "            np.array(pos_pro_time),\n",
    "            np.array(pos_prev_dates)[:, np.newaxis],\n",
    "            np.array(pos_cur_times)[:, np.newaxis],\n",
    "        ])\n",
    "        neg_pro = np.hstack([\n",
    "            np.array(neg_pro_content),\n",
    "            neg_pro_embeddings,\n",
    "            np.array(neg_pro_time),\n",
    "            np.array(neg_prev_dates)[:, np.newaxis],\n",
    "            np.array(neg_cur_times)[:, np.newaxis],\n",
    "        ])\n",
    "        \n",
    "        return_list = [np.vstack([pos_que, neg_que]), np.vstack([pos_pro, neg_pro])]\n",
    "        target = np.vstack([np.ones((self.pos_size, 1)), np.zeros((self.neg_size, 1))])\n",
    "        \n",
    "        return return_list, target\n",
    "    \n",
    "    \n",
    "    def __negative_que_prev_answer_date(self, pro, cur_time):\n",
    "        pro_dates = self.pro_answer_dates_dict[pro]\n",
    "        \n",
    "        index = np.searchsorted(pro_dates, cur_time)\n",
    "        if index == 0:\n",
    "            raise ValueError(\"Index cannot be zero.\")\n",
    "        return pro_dates[index-1]\n",
    "    \n",
    "    \n",
    "    def __convert(self, pairs):\n",
    "        x_que, x_pro = [], []\n",
    "        for que, pro in pairs:\n",
    "            stu = self.que_stu_dict[que]\n",
    "            \n",
    "            que_tags = []\n",
    "            pro_tags = []\n",
    "            stu_tags = []\n",
    "            \n",
    "            # Average embedding of question tags\n",
    "            for tag in self.que_tags.get(que, []):\n",
    "                que_tags.append(self.tag_emb.get(tag, np.zeros(10)))\n",
    "            if len(que_tags) == 0:\n",
    "                que_tags.append(np.zeros(10))\n",
    "            que_tag_emb = np.vstack(que_tags).mean(axis = 0).reshape(-1)\n",
    "            \n",
    "            # Average embedding of professional tags\n",
    "            for tag in self.pro_tags.get(pro, []):\n",
    "                pro_tags.append(self.tag_emb.get(tag, np.zeros(10)))\n",
    "            if len(pro_tags) == 0:\n",
    "                pro_tags.append(np.zeros(10))\n",
    "            pro_tag_emb = np.vstack(pro_tags).mean(axis = 0).reshape(-1)\n",
    "            \n",
    "            # Collect all question and student embeddings\n",
    "            que_emb = self.que_emb[que]\n",
    "            x_que.append(np.hstack([\n",
    "                que_emb,\n",
    "                que_tag_emb,\n",
    "            ]))\n",
    "            \n",
    "            # Collect all professional embeddings\n",
    "            ind_emb = self.ind_emb.get(self.pro_ind[pro], np.zeros(10))\n",
    "            x_pro.append(np.hstack([\n",
    "                ind_emb,\n",
    "                pro_tag_emb,\n",
    "            ]))\n",
    "        \n",
    "        return np.vstack(x_que), np.vstack(x_pro)\n",
    "    \n",
    "    \n",
    "    def convert_que(self, que):\n",
    "        x_que = []\n",
    "        que_tags = []\n",
    "            \n",
    "        # Average embedding of question tags\n",
    "        for tag in self.que_tags.get(que, []):\n",
    "            que_tags.append(self.tag_emb.get(tag, np.zeros(10)))\n",
    "        if len(que_tags) == 0:\n",
    "            que_tags.append(np.zeros(10))\n",
    "        que_tag_emb = np.vstack(que_tags).mean(axis = 0).reshape(-1)\n",
    "\n",
    "        # Collect all question and student embeddings\n",
    "        que_emb = self.que_emb[que]\n",
    "        x_que.append(np.hstack([que_emb,\n",
    "                                que_tag_emb,\n",
    "                                ]))\n",
    "        \n",
    "        return np.vstack(x_que)\n",
    "    \n",
    "    \n",
    "    def convert_pro(self, pro):\n",
    "        x_pro = []\n",
    "        pro_tags = []\n",
    "            \n",
    "        # Average embedding of professional tags\n",
    "        for tag in self.pro_tags.get(pro, []):\n",
    "            pro_tags.append(self.tag_emb.get(tag, np.zeros(10)))\n",
    "        if len(pro_tags) == 0:\n",
    "            pro_tags.append(np.zeros(10))\n",
    "        pro_tag_emb = np.vstack(pro_tags).mean(axis = 0).reshape(-1)\n",
    "\n",
    "        # Collect all professional embeddings\n",
    "        ind_emb = self.ind_emb.get(self.pro_ind[pro], np.zeros(10))\n",
    "        x_pro.append(np.hstack([ind_emb,\n",
    "                                pro_tag_emb\n",
    "                                ]))\n",
    "        \n",
    "        return np.vstack(x_pro)\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.ans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = BatchGenerator(64, 64, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator[0][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.8 ms ± 777 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "generator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%lprun -f generator.__getitem__ generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute some professionals from previous answer date distribution for every answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ans_date_added_dict.pickle', 'rb') as f:\n",
    "    ans_date_added_dict = pickle.load(f)\n",
    "with open('pro_last_answer_dates_dict.pickle', 'rb') as f:\n",
    "    pro_last_answer_dates_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_que_pro_dict = {row['answers_id']:(row['questions_id'], row['professionals_id'])\n",
    "                    for _, row in pp.qa_data.iterrows()}\n",
    "que_pro_set = {(row['questions_id'], row['professionals_id']) for _, row in pp.qa_data.iterrows()}\n",
    "pro_list = list(pp.prof_data['professionals_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_date_added_df = (pp.qa_data[['answers_id', 'answers_date_added_time']]\n",
    "                     .sort_values(by='answers_date_added_time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_list = list(ans_date_added_df.answers_id.values)\n",
    "with open('ans_list.pickle', 'wb') as f:\n",
    "    pickle.dump(ans_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49722"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(ans_list)).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999999995e-10"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf = 1 / (np.float64(1e9))\n",
    "np.log1p(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.62652683258057\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "inf = 1e9\n",
    "\n",
    "pro_cur_date = np.ones(len(pro_list)) * -inf\n",
    "pro_next_date = np.zeros(len(pro_list))\n",
    "pro_cur_idx = np.ones(len(pro_list), dtype=int) * -1\n",
    "pro_last_answer_dates_list = []\n",
    "\n",
    "ans_sampled_profs_dict = {}\n",
    "\n",
    "for i, pro in enumerate(pro_list):\n",
    "    pro_next_date[i] = pro_last_answer_dates_dict[pro][0]\n",
    "    pro_last_answer_dates_list.append(pro_last_answer_dates_dict[pro])\n",
    "\n",
    "for _, row in ans_date_added_df.iterrows():\n",
    "    ans = row['answers_id']\n",
    "    ans_date_added = row['answers_date_added_time']\n",
    "    \n",
    "    changed_pros_idx = np.nonzero(pro_next_date < ans_date_added)[0]\n",
    "    \n",
    "    for i in changed_pros_idx:\n",
    "        pro_cur_idx[i] += 1\n",
    "        idx = pro_cur_idx[i]\n",
    "        \n",
    "        pro_cur_date[i] = pro_next_date[i]\n",
    "        \n",
    "        if idx < pro_last_answer_dates_list[i].size:\n",
    "            pro_next_date[i] = pro_last_answer_dates_list[i][idx]\n",
    "        else:\n",
    "            pro_next_date[i] = inf\n",
    "    \n",
    "    # Substact last answer dates from the actual date the answer was added\n",
    "    distances = ans_date_added - np.array(pro_cur_date)\n",
    "    \n",
    "    # Apply log1p transformation to 1 / distances and normalize each entry\n",
    "    distances = np.log1p(1 / distances)\n",
    "    distances /= distances.sum()\n",
    "    \n",
    "    # Sample 50 professional from distribution of distances and choose 10 or less unique among them\n",
    "    sampled_pro_set = set(np.random.choice(pro_list, 50, p=distances))\n",
    "    \n",
    "    que, _ = ans_que_pro_dict[ans]\n",
    "    pros = sampled_pro_set.copy()\n",
    "    for pro in sampled_pro_set:\n",
    "        if (que, pro) in que_pro_set:\n",
    "            pros.remove(pro)\n",
    "    \n",
    "    pros = list(pros)[: min(10, len(pros))]\n",
    "    ans_sampled_profs_dict[ans] = pros\n",
    "\n",
    "total = time.time() - start\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcb3d96f74104351938c362893b77e33 : ['0c70d8f19f074a0581c1c05c9922b03b', '977bfe665d674798948d6fa481ced3ac']\n"
     ]
    }
   ],
   "source": [
    "for key, value in ans_sampled_profs_dict.items():\n",
    "    print(key, ':', value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in ans_sampled_profs_dict.items():\n",
    "    if len(value) == 0:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ans_sampled_profs_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(ans_sampled_profs_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ans_sampled_profs_dict.pickle', 'rb') as f:\n",
    "    ans_sampled_profs_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
