{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create class for data preprocessing required for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCreator:\n",
    "    \"\"\"\n",
    "    Class that imports initial datasets and creates additional datasets for convenience\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path='../../data/', created=False):\n",
    "        # Add data_path to class properties\n",
    "        self.data_path = data_path\n",
    "        \n",
    "        # Import all initial datasets\n",
    "        self.emails = pd.read_csv(data_path + 'emails.csv')\n",
    "        self.questions = pd.read_csv(data_path + 'questions.csv')\n",
    "        self.professionals = pd.read_csv(data_path + 'professionals.csv')\n",
    "        self.comments = pd.read_csv(data_path + 'comments.csv')\n",
    "        self.tag_users = pd.read_csv(data_path + 'tag_users.csv')\n",
    "        self.group_memberships = pd.read_csv(data_path + 'group_memberships.csv')\n",
    "        self.tags = pd.read_csv(data_path + 'tags.csv')\n",
    "        self.students = pd.read_csv(data_path + 'students.csv')\n",
    "        self.groups = pd.read_csv(data_path + 'groups.csv')\n",
    "        self.tag_questions = pd.read_csv(data_path + 'tag_questions.csv')\n",
    "        self.matches = pd.read_csv(data_path + 'matches.csv')\n",
    "        self.answers = pd.read_csv(data_path + 'answers.csv')\n",
    "        self.school_memberships = pd.read_csv(data_path + 'school_memberships.csv')\n",
    "        \n",
    "        if created:\n",
    "            # Load additional datasets from disk\n",
    "            self.qa_data = pd.read_csv(self.data_path + 'qa_data.csv')\n",
    "            self.ques_data = pd.read_csv(self.data_path + 'ques_data.csv')\n",
    "            self.prof_data = pd.read_csv(self.data_path + 'prof_data.csv')\n",
    "            self.stud_data = pd.read_csv(self.data_path + 'stud_data.csv')\n",
    "        else:\n",
    "            # Create additional datasets and save them to disk\n",
    "            self.additional_dataset_creation()\n",
    "    \n",
    "    \n",
    "    def additional_dataset_creation(self):\n",
    "        \"\"\"\n",
    "        Creates additional datasets for futher processing and save them to disk.\n",
    "        \"\"\"\n",
    "        # Create temporary dataset for further processing\n",
    "        all_data = self.all_data_dataset_creation()\n",
    "        \n",
    "        # Create question-answer pairs dataset called qa_data\n",
    "        self.qa_data = self.qa_data_dataset_creation(all_data)\n",
    "        \n",
    "        # Create answered questions dataset called ques_data and\n",
    "        self.ques_data = self.qa_data[[\n",
    "            'questions_id', 'questions_title', 'questions_body', 'questions_date_added'\n",
    "        ]]\n",
    "        \n",
    "        # Create dataset called prof_data compirising data of professionals\n",
    "        # who answered at least one question\n",
    "        self.prof_data = self.prof_data_dataset_creation(all_data)\n",
    "        \n",
    "        # Create dataset called stud_data compirising data of students\n",
    "        # who asked at least one answered question\n",
    "        self.stud_data = self.stud_data_dataset_creation(all_data)\n",
    "        \n",
    "        # Save new datasets to disc\n",
    "        self.qa_data.to_csv(self.data_path + 'qa_data.csv', index=False)\n",
    "        self.ques_data.to_csv(self.data_path + 'ques_data.csv', index=False)\n",
    "        self.prof_data.to_csv(self.data_path + 'prof_data.csv', index=False)\n",
    "        self.stud_data.to_csv(self.data_path + 'stud_data.csv', index=False)\n",
    "    \n",
    "    \n",
    "    def all_data_dataset_creation(self):\n",
    "        \"\"\"\n",
    "        Merges questions, answers, professionals and students datasets\n",
    "        to get temporary dataset for further processing\n",
    "        \"\"\"\n",
    "        # Merge questions with answers and delete not answered questions\n",
    "        all_data = self.questions.merge(self.answers, how='right', left_on='questions_id', right_on='answers_question_id')\n",
    "        \n",
    "        # Merge with professionals and students (students asked, professionals answered)\n",
    "        # Maybe change this in the future by taking care of professional who change status to students and vise versa\n",
    "        all_data = all_data.merge(self.professionals, how='inner', left_on='answers_author_id', right_on='professionals_id')\n",
    "        all_data = all_data.merge(self.students, how='inner', left_on='questions_author_id', right_on='students_id')\n",
    "        \n",
    "        # Transform all dates from string representation to python datetime object\n",
    "        all_data.answers_date_added = pd.to_datetime(all_data.answers_date_added)\n",
    "        all_data.questions_date_added = pd.to_datetime(all_data.questions_date_added)\n",
    "        \n",
    "        # Add questions_age feature, which represents amount of time\n",
    "        # from question emergence to a particular answer to that question\n",
    "        all_data['questions_age'] = all_data.answers_date_added - all_data.questions_date_added\n",
    "        \n",
    "        return all_data\n",
    "    \n",
    "    \n",
    "    def qa_data_dataset_creation(self, all_data):\n",
    "        \"\"\"\n",
    "        Creates question-answer pairs dataset called qa_data_data\n",
    "        \"\"\"\n",
    "        # Temporary qa_data representation\n",
    "        qa_data = all_data\n",
    "        \n",
    "        # Select only unique professionals\n",
    "        temp = qa_data[['professionals_id', 'answers_date_added', 'answers_id']]\n",
    "        prof_unique = pd.DataFrame(temp.professionals_id.unique(), columns=['professionals_id'])\n",
    "        prof_unique = prof_unique.merge(self.professionals, how='left', on='professionals_id')\n",
    "        \n",
    "        # For every professional add a \"dummy\" question with answer date being professional's registration date\n",
    "        prof_unique['answers_id'] = list(None for _ in range(prof_unique.shape[0]))\n",
    "        prof_unique['answers_date_added'] = prof_unique['professionals_date_joined']\n",
    "        prof_unique = prof_unique[['professionals_id', 'answers_date_added', 'answers_id']]\n",
    "        \n",
    "        # Add \"dummy\" questions to all questions\n",
    "        temp = pd.concat([temp, prof_unique])\n",
    "        \n",
    "        # Sort by professionals and answer dates\n",
    "        temp = temp.sort_values(by=['professionals_id', 'answers_date_added']).reset_index(drop=True)\n",
    "        \n",
    "        # Get the sorted representation of the answers_date_added and shift the index down by one\n",
    "        # so that current question is aligned with previous question answer date\n",
    "        last_answer_date = pd.DataFrame({'professionals_last_answer_date': temp.answers_date_added})\n",
    "        last_answer_date.index += 1\n",
    "        \n",
    "        # Add the professionals_last_answer_date column to temp\n",
    "        temp = temp.merge(last_answer_date, left_index=True, right_index=True)\n",
    "        temp.dropna(subset=['answers_id'], inplace=True)\n",
    "        temp.drop(columns=['professionals_id', 'answers_date_added'], inplace=True)\n",
    "        \n",
    "        # Add professionals_last_answer_date column to qa_data \n",
    "        qa_data = qa_data.merge(temp, on='answers_id')\n",
    "        \n",
    "        # Transform dates from string representation to python datetime object\n",
    "        qa_data.professionals_last_answer_date = pd.to_datetime(qa_data.professionals_last_answer_date)\n",
    "        \n",
    "        # Final qa_data representation\n",
    "        qa_data = qa_data[[\n",
    "            'questions_id', 'questions_author_id', 'questions_title', 'questions_body',\n",
    "            'questions_date_added', 'answers_id', 'answers_author_id', 'answers_body',\n",
    "            'answers_date_added', 'questions_age', 'professionals_last_answer_date'\n",
    "        ]]\n",
    "        \n",
    "        return qa_data\n",
    "    \n",
    "    \n",
    "    def prof_data_dataset_creation(self, all_data):\n",
    "        \"\"\"\n",
    "        Creates dataset called prof_data compirising data of professionals who answered at least one question\n",
    "        \"\"\"\n",
    "        # Select only professionals who answered at least one question\n",
    "        active_professionals = pd.DataFrame({'professionals_id': all_data.professionals_id.unique()})\n",
    "        prof_data = self.professionals.merge(active_professionals, how='right', on='professionals_id')\n",
    "        prof_data.professionals_date_joined = pd.to_datetime(prof_data.professionals_date_joined)\n",
    "        \n",
    "        # Count the number of answered questions by each professional\n",
    "        number_answered = all_data[['questions_id', 'professionals_id']].groupby('professionals_id').count()\n",
    "        number_answered = number_answered.rename({'questions_id': 'professionals_questions_answered'}, axis=1)\n",
    "        \n",
    "        # Add professionals_questions_answered feature to prof_data\n",
    "        prof_data = prof_data.merge(number_answered, left_on='professionals_id', right_index=True)\n",
    "        \n",
    "        # Get average question age for every professional among questions he answered\n",
    "        average_question_age = (\n",
    "            all_data.groupby('professionals_id')\n",
    "            .questions_age.mean(numeric_only=False)\n",
    "        )\n",
    "        average_question_age = pd.DataFrame({'professionals_average_question_age': average_question_age})\n",
    "        \n",
    "        # Add professionals_average_question_age feature to prof_data\n",
    "        prof_data = prof_data.merge(average_question_age, on='professionals_id')\n",
    "        \n",
    "        return prof_data\n",
    "    \n",
    "    \n",
    "    def stud_data_dataset_creation(self, all_data):\n",
    "        \"\"\"\n",
    "        Creates dataset called stud_data compirising data of students who asked at least one answered question\n",
    "        \"\"\"\n",
    "        # Select only students who asked at least one answered question\n",
    "        active_students = pd.DataFrame({'students_id': all_data.students_id.unique()})\n",
    "        stud_data = self.students.merge(active_students, how='right', on='students_id')\n",
    "        stud_data.students_date_joined = pd.to_datetime(stud_data.students_date_joined)\n",
    "        \n",
    "        # Count the number of asked questions by each student\n",
    "        number_asked = all_data[['questions_id', 'students_id']].groupby('students_id').count()\n",
    "        number_asked = number_asked.rename({'questions_id': 'students_questions_asked'}, axis=1)\n",
    "        \n",
    "        # Add students_questions_answered feature to stud_data\n",
    "        stud_data = stud_data.merge(number_asked, left_on='students_id', right_index=True)\n",
    "        \n",
    "        # Get average question age for every student among questions he asked that were answered\n",
    "        average_question_age = (\n",
    "            all_data.groupby('students_id')\n",
    "            .questions_age.mean(numeric_only=False)\n",
    "        )\n",
    "        average_question_age = pd.DataFrame({'students_average_question_age': average_question_age})\n",
    "        \n",
    "        # Add professionals_average_question_age feature to prof_data\n",
    "        stud_data = stud_data.merge(average_question_age, on='students_id')\n",
    "        \n",
    "        return stud_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator = DatasetCreator(created=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>questions_body</th>\n",
       "      <th>questions_date_added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>Teacher   career   question</td>\n",
       "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
       "      <td>2016-04-26 11:14:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7a0d4bc67b1c492fb06fe455b1c07faf</td>\n",
       "      <td>Teacher's Qualification</td>\n",
       "      <td>Hi I am doing my 10th Standard. What are the q...</td>\n",
       "      <td>2016-04-26 10:59:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7a0d4bc67b1c492fb06fe455b1c07faf</td>\n",
       "      <td>Teacher's Qualification</td>\n",
       "      <td>Hi I am doing my 10th Standard. What are the q...</td>\n",
       "      <td>2016-04-26 10:59:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7a0d4bc67b1c492fb06fe455b1c07faf</td>\n",
       "      <td>Teacher's Qualification</td>\n",
       "      <td>Hi I am doing my 10th Standard. What are the q...</td>\n",
       "      <td>2016-04-26 10:59:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0f1d6a4f276c4a05878dd48e03e52289</td>\n",
       "      <td>what kind of  college could i go  to for a soc...</td>\n",
       "      <td>I like soccer because i been playing sense i w...</td>\n",
       "      <td>2016-05-19 22:16:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       questions_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54   \n",
       "1  7a0d4bc67b1c492fb06fe455b1c07faf   \n",
       "2  7a0d4bc67b1c492fb06fe455b1c07faf   \n",
       "3  7a0d4bc67b1c492fb06fe455b1c07faf   \n",
       "4  0f1d6a4f276c4a05878dd48e03e52289   \n",
       "\n",
       "                                     questions_title  \\\n",
       "0                        Teacher   career   question   \n",
       "1                            Teacher's Qualification   \n",
       "2                            Teacher's Qualification   \n",
       "3                            Teacher's Qualification   \n",
       "4  what kind of  college could i go  to for a soc...   \n",
       "\n",
       "                                      questions_body questions_date_added  \n",
       "0  What  is  a  maths  teacher?   what  is  a  ma...  2016-04-26 11:14:26  \n",
       "1  Hi I am doing my 10th Standard. What are the q...  2016-04-26 10:59:44  \n",
       "2  Hi I am doing my 10th Standard. What are the q...  2016-04-26 10:59:44  \n",
       "3  Hi I am doing my 10th Standard. What are the q...  2016-04-26 10:59:44  \n",
       "4  I like soccer because i been playing sense i w...  2016-05-19 22:16:25  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creator.ques_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
