{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, re\n",
    "from keras import Model\n",
    "from sklearn.neighbors import KDTree\n",
    "from processors import QueProc\n",
    "from models import ContentModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('proc_data/train_que_data.pkl', 'rb') as f:\n",
    "    train_que_data = pickle.load(f)\n",
    "with open('proc_data/train_stu_data.pkl', 'rb') as f:\n",
    "    train_stu_data = pickle.load(f)\n",
    "with open('proc_data/train_pro_data.pkl', 'rb') as f:\n",
    "    train_pro_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 33\n",
      "27 32\n"
     ]
    }
   ],
   "source": [
    "que_cols = list(train_stu_data.columns[2:]) + list(train_que_data.columns[2:]) + ['questions_current_time']\n",
    "pro_cols = list(train_pro_data.columns[2:]) + ['professionals_current_time']\n",
    "print(len(que_cols), len(pro_cols))\n",
    "\n",
    "que_content_mask = np.zeros(len(que_cols)-1, dtype=bool) # Change\n",
    "for i, col in enumerate(que_cols[:-1]): # Change\n",
    "    if re.search(r'emb', col):\n",
    "        que_content_mask[i] = True\n",
    "\n",
    "pro_content_mask = np.zeros(len(pro_cols)-1, dtype=bool) # Change\n",
    "for i, col in enumerate(pro_cols[:-1]): # Change\n",
    "    if re.search(r'emb', col):\n",
    "        pro_content_mask[i] = True\n",
    "print(que_content_mask.size, pro_content_mask.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_model = ContentModel(\n",
    "    len(que_cols), que_content_mask,\n",
    "    len(pro_cols), pro_content_mask,\n",
    "    10, 5,\n",
    ")\n",
    "content_model.load_weights('content_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    \"\"\"\n",
    "    Class that creates KNN tree for professionals\n",
    "    and which is used to find closest professionals for a particular question\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, content_model: ContentModel):\n",
    "        \"\"\"\n",
    "        Prepare required datasets and create KNN tree for professionals\n",
    "        based on latent vectors from content model\n",
    "        :param content_model: compiled model of class ContentModel\n",
    "        \"\"\"\n",
    "        # load raw datasets\n",
    "        self.pro = pd.read_csv('../../data/professionals.csv')\n",
    "        \n",
    "        tags = pd.read_csv('../../data/tags.csv')\n",
    "        tag_pro = pd.read_csv('../../data/tag_users.csv').merge(\n",
    "            tags, left_on='tag_users_tag_id', right_on='tags_tag_id')\n",
    "        \n",
    "        # append aggregated subscribed tags to each professional\n",
    "        pro_tags = tag_pro.groupby('tag_users_user_id', as_index=False)[['tags_tag_name']] \\\n",
    "            .aggregate(lambda x: ' '.join(set(x))) \\\n",
    "            .rename({'tag_users_user_id': 'professionals_id',\n",
    "                     'tags_tag_name': 'professionals_subscribed_tags'}, axis=1)\n",
    "        self.pro = self.pro.merge(pro_tags, how='left', on='professionals_id')\n",
    "        \n",
    "        # load datasets with preprocessed features\n",
    "        with open('proc_data/test_stu_data.pkl', 'rb') as f:\n",
    "            self.stu_data = pickle.load(f)\n",
    "        with open('proc_data/test_pro_data.pkl', 'rb') as f:\n",
    "            self.pro_data = pickle.load(f)\n",
    "        \n",
    "        self.content_model = content_model\n",
    "        \n",
    "        # prepare professional features\n",
    "        pro_dict = {pro: group.values[-1, 2:] for pro, group in self.pro_data.groupby('professionals_id')}\n",
    "        self.pros = np.array(list(pro_dict.keys()))\n",
    "        pro_feat = np.vstack(pro_dict.values())\n",
    "        pro_feat = np.hstack([pro_feat, np.zeros((pro_feat.shape[0], 1))])\n",
    "        \n",
    "        # prepare student features\n",
    "        stu_dict = {stu: group.iloc[-1, 2:] for stu, group in self.stu_data.groupby('students_id')}\n",
    "        self.stu_data = pd.DataFrame.from_dict(stu_dict).transpose()\n",
    "        \n",
    "        # compute latent vectors for professionals from content model\n",
    "        pro_lat_model = Model(inputs=content_model.inputs[1], outputs=content_model.pro_encoded)\n",
    "        pro_lat_vecs = pro_lat_model.predict(pro_feat)\n",
    "        \n",
    "        # create model that receieves question features and returns question latent vector\n",
    "        self.que_lat_model = Model(inputs=content_model.inputs[0], outputs=content_model.que_encoded)\n",
    "        \n",
    "        # create KNN tree consisting of professional latent vectors\n",
    "        self.lat_vec_tree = KDTree(pro_lat_vecs)\n",
    "        \n",
    "        # initialize QueProc\n",
    "        self.que_proc = QueProc(oblige_fit=False, path='dump/')\n",
    "    \n",
    "    \n",
    "    def predict_df(self, que_df: pd.DataFrame, que_tags: pd.DataFrame,\n",
    "                   top: int=10, pro_expand: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns top professionals for given questions\n",
    "        :param que_df: DataFrame of question data\n",
    "        :param que_tags: DataFrame of question_tags\n",
    "        :param top: how many top professionals to return\n",
    "        :param pro_expand: whether to add professional data to returned DataFrame\n",
    "        \"\"\"\n",
    "        que_df['questions_date_added'] = pd.to_datetime(que_df['questions_date_added'])\n",
    "        \n",
    "        # prepare student features\n",
    "        stu_feat = que_df[['questions_author_id']] \\\n",
    "            .merge(self.stu_data, how='left', left_on='questions_author_id', right_index=True).values[:, 1:]\n",
    "        \n",
    "        # prepare question features and add them to student features\n",
    "        que_feat = self.que_proc.transform(que_df, que_tags).values[:, 2:]\n",
    "        que_feat = np.hstack([stu_feat, que_feat, np.zeros((que_feat.shape[0], 1))])\n",
    "        \n",
    "        # get top professionals for questions\n",
    "        que_lat_vecs = self.que_lat_model.predict(que_feat)\n",
    "        dists, pros = self.lat_vec_tree.query(que_lat_vecs, k=top)\n",
    "        pros = self.pros[pros]\n",
    "        scores = np.exp(-dists)\n",
    "        ques = que_df['questions_id'].values\n",
    "        \n",
    "        # create que-pro-score tuples\n",
    "        tuples = []\n",
    "        for i, que in enumerate(ques):\n",
    "            for j, pro in enumerate(pros[i]):\n",
    "                tuples.append((que, pro, scores[i, j]))\n",
    "        \n",
    "        # create DataFrame from que-pro-score tuples\n",
    "        score_df = pd.DataFrame(tuples, columns=['questions_id', 'professionals_id', 'professionals_score'])\n",
    "        \n",
    "        if pro_expand:\n",
    "            # add professionals features\n",
    "            score_df = score_df.merge(self.pro, how='left', on='professionals_id')\n",
    "        \n",
    "        return score_df\n",
    "    \n",
    "    \n",
    "    def predict_dict(self, que_dict: dict, top: int=10, pro_expand: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Converts dictionary of questions into desired form, then call predict_df method\n",
    "        :param que_dict: dictionary of question data\n",
    "        :param top: how many top professionals to return\n",
    "        :param pro_expand: whether to add professional data to returned DataFrame\n",
    "        \"\"\"\n",
    "        # get DataFrame from dict\n",
    "        que_df = pd.DataFrame.from_dict(que_dict)\n",
    "        ques = que_df['questions_id'].values\n",
    "        \n",
    "        # create que-tag tuples\n",
    "        tuples = []\n",
    "        for i, tags in enumerate(que_df['questions_tags'].values):\n",
    "            que = ques[i]\n",
    "            for tag in tags.split(' '):\n",
    "                tuples.append((que, tag))\n",
    "        \n",
    "        # create DataFrame from que-tag tuples\n",
    "        que_tags = pd.DataFrame(tuples, columns=['tag_questions_question_id', 'tags_tag_name'])\n",
    "        \n",
    "        que_df.drop(columns='questions_tags', inplace=True)\n",
    "        \n",
    "        # pass computed DataFrames to predict_df method\n",
    "        return self.predict_df(que_df, que_tags, top, pro_expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(content_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_dict = {\n",
    "    'questions_id': ['332a511f1569444485cf7a7a556a5e54'],\n",
    "    'questions_author_id': ['8f6f374ffd834d258ab69d376dd998f5'],\n",
    "    'questions_date_added': ['2016-04-26 11:14:26'],\n",
    "    'questions_title': ['Teacher   career   question'],\n",
    "    'questions_body': ['What  is  a  maths  teacher?   what  is  a  maths  teacher  useful? #college #professor #lecture'],\n",
    "    'questions_tags': ['college professor lecture']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>professionals_id</th>\n",
       "      <th>professionals_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>505fb5d32c1e41c5affe896328644832</td>\n",
       "      <td>0.858492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>fe151e90cc154d7da63b14fe6ed3c3e5</td>\n",
       "      <td>0.846544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>3ce003197d28478884ae0183a645d968</td>\n",
       "      <td>0.840861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>eab382099e2b4b03abdcbb4d85b5ec0d</td>\n",
       "      <td>0.828587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>d754969c1565445db381bb2d75273ee1</td>\n",
       "      <td>0.808249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>dcffe989be294141a523d71f3908c6bb</td>\n",
       "      <td>0.806587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>bf6edb3e76b94594a982c5776764cf75</td>\n",
       "      <td>0.797939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>aad8c9eaabf24305912b30a5d58137f6</td>\n",
       "      <td>0.795392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>9bf67236d34743768be67bd789dc618e</td>\n",
       "      <td>0.793254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>c2c6bf81c2e444ff834d98b58ab37687</td>\n",
       "      <td>0.792261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       questions_id                  professionals_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  505fb5d32c1e41c5affe896328644832   \n",
       "1  332a511f1569444485cf7a7a556a5e54  fe151e90cc154d7da63b14fe6ed3c3e5   \n",
       "2  332a511f1569444485cf7a7a556a5e54  3ce003197d28478884ae0183a645d968   \n",
       "3  332a511f1569444485cf7a7a556a5e54  eab382099e2b4b03abdcbb4d85b5ec0d   \n",
       "4  332a511f1569444485cf7a7a556a5e54  d754969c1565445db381bb2d75273ee1   \n",
       "5  332a511f1569444485cf7a7a556a5e54  dcffe989be294141a523d71f3908c6bb   \n",
       "6  332a511f1569444485cf7a7a556a5e54  bf6edb3e76b94594a982c5776764cf75   \n",
       "7  332a511f1569444485cf7a7a556a5e54  aad8c9eaabf24305912b30a5d58137f6   \n",
       "8  332a511f1569444485cf7a7a556a5e54  9bf67236d34743768be67bd789dc618e   \n",
       "9  332a511f1569444485cf7a7a556a5e54  c2c6bf81c2e444ff834d98b58ab37687   \n",
       "\n",
       "   professionals_score  \n",
       "0             0.858492  \n",
       "1             0.846544  \n",
       "2             0.840861  \n",
       "3             0.828587  \n",
       "4             0.808249  \n",
       "5             0.806587  \n",
       "6             0.797939  \n",
       "7             0.795392  \n",
       "8             0.793254  \n",
       "9             0.792261  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_dict(que_dict, pro_expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 ms ± 881 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "predictor.predict_dict(que_dict, pro_expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
