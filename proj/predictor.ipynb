{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, re\n",
    "from keras import Model\n",
    "from sklearn.neighbors import KDTree\n",
    "from processors import QueProc, ProProc\n",
    "from models import ContentModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('proc_data/train_que_data.pkl', 'rb') as f:\n",
    "    train_que_data = pickle.load(f)\n",
    "with open('proc_data/train_stu_data.pkl', 'rb') as f:\n",
    "    train_stu_data = pickle.load(f)\n",
    "with open('proc_data/train_pro_data.pkl', 'rb') as f:\n",
    "    train_pro_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 33\n",
      "27 32\n"
     ]
    }
   ],
   "source": [
    "que_cols = list(train_stu_data.columns[2:]) + list(train_que_data.columns[2:]) + ['questions_current_time']\n",
    "pro_cols = list(train_pro_data.columns[2:]) + ['professionals_current_time']\n",
    "print(len(que_cols), len(pro_cols))\n",
    "\n",
    "que_content_mask = np.zeros(len(que_cols)-1, dtype=bool) # Change\n",
    "for i, col in enumerate(que_cols[:-1]): # Change\n",
    "    if re.search(r'emb', col):\n",
    "        que_content_mask[i] = True\n",
    "\n",
    "pro_content_mask = np.zeros(len(pro_cols)-1, dtype=bool) # Change\n",
    "for i, col in enumerate(pro_cols[:-1]): # Change\n",
    "    if re.search(r'emb', col):\n",
    "        pro_content_mask[i] = True\n",
    "print(que_content_mask.size, pro_content_mask.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_model = ContentModel(\n",
    "    len(que_cols), que_content_mask,\n",
    "    len(pro_cols), pro_content_mask,\n",
    "    10, 5,\n",
    ")\n",
    "content_model.load_weights('content_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    \"\"\"\n",
    "    Class that creates KNN tree for professionals\n",
    "    and which is used to find closest professionals for a particular question\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, content_model: ContentModel):\n",
    "        \"\"\"\n",
    "        Prepare required datasets and create KNN tree for professionals\n",
    "        based on latent vectors from content model\n",
    "        :param content_model: compiled model of class ContentModel\n",
    "        \"\"\"\n",
    "        self.content_model = content_model\n",
    "        \n",
    "        # load raw datasets\n",
    "        self.que = pd.read_csv('../../data/questions.csv')\n",
    "        self.ans = pd.read_csv('../../data/answers.csv')\n",
    "        self.stu = pd.read_csv('../../data/students.csv')\n",
    "        self.pro = pd.read_csv('../../data/professionals.csv')\n",
    "        \n",
    "        # process date columns\n",
    "        for df, col in [(self.que, 'questions_date_added'), (self.ans, 'answers_date_added')]:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "        \n",
    "        # form question-student pairs dataframe\n",
    "        que_stu = self.que.merge(self.stu, left_on='questions_author_id', right_on='students_id') \\\n",
    "            [['questions_id', 'students_id']]\n",
    "        \n",
    "        # load and merge raw tag datasets\n",
    "        tags = pd.read_csv('../../data/tags.csv')\n",
    "        tag_que = pd.read_csv('../../data/tag_questions.csv').merge(\n",
    "            tags, left_on='tag_questions_tag_id', right_on='tags_tag_id')\n",
    "        tag_pro = pd.read_csv('../../data/tag_users.csv').merge(\n",
    "            tags, left_on='tag_users_tag_id', right_on='tags_tag_id')\n",
    "        \n",
    "        # append tags to each question\n",
    "        que_tags = tag_que.groupby('tag_questions_question_id', as_index=False)[['tags_tag_name']] \\\n",
    "            .aggregate(lambda x: ' '.join(set(x))) \\\n",
    "            .rename({'tag_questions_question_id': 'questions_id',\n",
    "                     'tags_tag_name': 'questions_tags'}, axis=1)\n",
    "        self.que = self.que.merge(que_tags, how='left', on='questions_id')\n",
    "        \n",
    "        # append subscribed tags to each professional\n",
    "        pro_tags = tag_pro.groupby('tag_users_user_id', as_index=False)[['tags_tag_name']] \\\n",
    "            .aggregate(lambda x: ' '.join(set(x))) \\\n",
    "            .rename({'tag_users_user_id': 'professionals_id',\n",
    "                     'tags_tag_name': 'professionals_subscribed_tags'}, axis=1)\n",
    "        self.pro = self.pro.merge(pro_tags, how='left', on='professionals_id')\n",
    "        \n",
    "        # load datasets with preprocessed features\n",
    "        with open('proc_data/test_que_data.pkl', 'rb') as f:\n",
    "            self.que_data = pickle.load(f)\n",
    "        with open('proc_data/test_stu_data.pkl', 'rb') as f:\n",
    "            self.stu_data = pickle.load(f)\n",
    "        with open('proc_data/test_pro_data.pkl', 'rb') as f:\n",
    "            self.pro_data = pickle.load(f)\n",
    "        \n",
    "        # prepare student features\n",
    "        stu_dict = {stu: group.iloc[-1, 2:] for stu, group in self.stu_data.groupby('students_id')}\n",
    "        self.stu_data = pd.DataFrame.from_dict(stu_dict).transpose()\n",
    "        \n",
    "        # prepare student features for questions from que_data\n",
    "        stus = self.que_data.merge(que_stu, how='left', on='questions_id')[['students_id']]\n",
    "        stu_feat = stus.merge(self.stu_data, how='left', left_on='students_id', right_index=True).values[:, 1:]\n",
    "        \n",
    "        # prepare question features and add them to student features\n",
    "        self.ques = self.que_data['questions_id'].values\n",
    "        que_feat = self.que_data.values[:, 2:]\n",
    "        que_feat = np.hstack([stu_feat, que_feat, np.zeros((que_feat.shape[0], 1))])\n",
    "        \n",
    "        # prepare professional features\n",
    "        pro_dict = {pro: group.values[-1, 2:] for pro, group in self.pro_data.groupby('professionals_id')}\n",
    "        self.pros = np.array(list(pro_dict.keys()))\n",
    "        pro_feat = np.vstack(pro_dict.values())\n",
    "        pro_feat = np.hstack([pro_feat, np.zeros((pro_feat.shape[0], 1))])\n",
    "        \n",
    "        # create two models that receieve question and professional features respectively\n",
    "        # and return their latent vectors\n",
    "        self.que_lat_model = Model(inputs=content_model.inputs[0], outputs=content_model.que_encoded)\n",
    "        self.pro_lat_model = Model(inputs=content_model.inputs[1], outputs=content_model.pro_encoded)\n",
    "        \n",
    "        # compute latent vectors for questions and professionals\n",
    "        que_lat_vecs = self.que_lat_model.predict(que_feat)\n",
    "        pro_lat_vecs = self.pro_lat_model.predict(pro_feat)\n",
    "        \n",
    "        # create two KNN trees consisting of question and professional latent vectors\n",
    "        self.que_tree = KDTree(que_lat_vecs)\n",
    "        self.pro_tree = KDTree(pro_lat_vecs)\n",
    "        \n",
    "        # initialize QueProc and ProProc\n",
    "        self.que_proc = QueProc(oblige_fit=False, path='dump/')\n",
    "        self.pro_proc = ProProc(oblige_fit=False, path='dump/')\n",
    "    \n",
    "    \n",
    "    def find_pros_by_que(self, que_df: pd.DataFrame, que_tags: pd.DataFrame,\n",
    "                         top: int=10, expand: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns top professionals for given questions\n",
    "        :param que_df: DataFrame of question data\n",
    "        :param que_tags: DataFrame of question tags\n",
    "        :param top: how many top professionals to return\n",
    "        :param expand: whether to add professional data to returned DataFrame\n",
    "        \"\"\"\n",
    "        que_df['questions_date_added'] = pd.to_datetime(que_df['questions_date_added'])\n",
    "        \n",
    "        # prepare student features\n",
    "        stu_feat = que_df[['questions_author_id']] \\\n",
    "            .merge(self.stu_data, how='left', left_on='questions_author_id', right_index=True).values[:, 1:]\n",
    "        \n",
    "        # prepare question features and add them to student features\n",
    "        que_feat = self.que_proc.transform(que_df, que_tags).values[:, 2:]\n",
    "        que_feat = np.hstack([stu_feat, que_feat, np.zeros((que_feat.shape[0], 1))])\n",
    "        \n",
    "        # get top professionals for questions\n",
    "        que_lat_vecs = self.que_lat_model.predict(que_feat)\n",
    "        dists, pros = self.pro_tree.query(que_lat_vecs, k=top)\n",
    "        pros = self.pros[pros]\n",
    "        scores = np.exp(-dists)\n",
    "        ques = que_df['questions_id'].values\n",
    "        \n",
    "        # create question-professional-score tuples\n",
    "        tuples = []\n",
    "        for i, que in enumerate(ques):\n",
    "            for j, pro in enumerate(pros[i]):\n",
    "                tuples.append((que, pro, scores[i, j]))\n",
    "        \n",
    "        # create DataFrame from tuples\n",
    "        score_df = pd.DataFrame(tuples, columns=['questions_id', 'professionals_id', 'professionals_score'])\n",
    "        \n",
    "        if expand:\n",
    "            # add professionals features\n",
    "            score_df = score_df.merge(self.pro, how='left', on='professionals_id')\n",
    "        \n",
    "        return score_df\n",
    "    \n",
    "    \n",
    "    def find_ques_by_que(self, que_df: pd.DataFrame, que_tags: pd.DataFrame,\n",
    "                         top: int=10, expand: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns top similar questions for given questions\n",
    "        :param que_df: DataFrame of question data\n",
    "        :param que_tags: DataFrame of question tags\n",
    "        :param top: how many top professionals to return\n",
    "        :param expand: whether to add professional data to returned DataFrame\n",
    "        \"\"\"\n",
    "        que_df['questions_date_added'] = pd.to_datetime(que_df['questions_date_added'])\n",
    "        \n",
    "        # prepare student features\n",
    "        stu_feat = que_df[['questions_author_id']] \\\n",
    "            .merge(self.stu_data, how='left', left_on='questions_author_id', right_index=True).values[:, 1:]\n",
    "        \n",
    "        # prepare question features and add them to student features\n",
    "        que_feat = self.que_proc.transform(que_df, que_tags).values[:, 2:]\n",
    "        que_feat = np.hstack([stu_feat, que_feat, np.zeros((que_feat.shape[0], 1))])\n",
    "        \n",
    "        # get top similar questions for initial questions\n",
    "        que_lat_vecs = self.que_lat_model.predict(que_feat)\n",
    "        dists, sim_ques = self.que_tree.query(que_lat_vecs, k=top)\n",
    "        sim_ques = self.ques[sim_ques]\n",
    "        scores = np.exp(-dists)\n",
    "        ques = que_df['questions_id'].values\n",
    "        \n",
    "        # create question-similar_question-score tuples\n",
    "        tuples = []\n",
    "        for i, que in enumerate(ques):\n",
    "            for j, sim_que in enumerate(sim_ques[i]):\n",
    "                tuples.append((que, sim_que, scores[i, j]))\n",
    "        \n",
    "        # create DataFrame from tuples\n",
    "        score_df = pd.DataFrame(tuples, columns=['initial_questions_id', 'questions_id', 'questions_score'])\n",
    "        \n",
    "        if expand:\n",
    "            # add similar question features\n",
    "            score_df = score_df.merge(self.que, how='left', on='questions_id')\n",
    "        \n",
    "        return score_df\n",
    "    \n",
    "    \n",
    "    def convert_que_dict(self, que_dict: dict) -> (pd.DataFrame, pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Converts dictionary of question data into desired form\n",
    "        :param que_dict: dictionary of question data\n",
    "        \"\"\"\n",
    "        # get DataFrame from dict\n",
    "        que_df = pd.DataFrame.from_dict(que_dict)\n",
    "        ques = que_df['questions_id'].values\n",
    "        \n",
    "        # create question-tag tuples\n",
    "        tuples = []\n",
    "        for i, tags in enumerate(que_df['questions_tags'].values):\n",
    "            que = ques[i]\n",
    "            for tag in tags.split(' '):\n",
    "                tuples.append((que, tag))\n",
    "        \n",
    "        # create DataFrame from tuples\n",
    "        que_tags = pd.DataFrame(tuples, columns=['tag_questions_question_id', 'tags_tag_name'])\n",
    "        que_df.drop(columns='questions_tags', inplace=True)\n",
    "        \n",
    "        return que_df, que_tags\n",
    "    \n",
    "    \n",
    "    def find_ques_by_pro(self, pro_df: pd.DataFrame, pro_tags: pd.DataFrame,\n",
    "                         top: int=10, expand: bool=False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns top questions for given professionals\n",
    "        :param pro_df: DataFrame of professional data\n",
    "        :param pro_tags: DataFrame of professional subscribed tags\n",
    "        :param top: how many top professionals to return\n",
    "        :param expand: whether to add professional data to returned DataFrame\n",
    "        \"\"\"\n",
    "        pro_df['professionals_date_joined'] = pd.to_datetime(pro_df['professionals_date_joined'])\n",
    "        \n",
    "        # prepare professional features\n",
    "        pro_feat = self.pro_proc.transform(pro_df, self.que, self.ans, pro_tags).values[:, 2:]\n",
    "        pro_feat = np.hstack([pro_feat, np.zeros((pro_feat.shape[0], 1))])\n",
    "        \n",
    "        # get top questions for professionals\n",
    "        pro_lat_vecs = self.pro_lat_model.predict(pro_feat)\n",
    "        dists, ques = self.que_tree.query(pro_lat_vecs, k=top)\n",
    "        ques = self.ques[ques]\n",
    "        scores = np.exp(-dists)\n",
    "        pros = pro_df['professionals_id'].values\n",
    "        \n",
    "        # create professional-question-score tuples\n",
    "        tuples = []\n",
    "        for i, pro in enumerate(pros):\n",
    "            for j, que in enumerate(ques[i]):\n",
    "                tuples.append((pro, que, scores[i, j]))\n",
    "        \n",
    "        # create DataFrame from tuples\n",
    "        score_df = pd.DataFrame(tuples, columns=['professionals_id', 'questions_id', 'questions_score'])\n",
    "        \n",
    "        if expand:\n",
    "            # add question features\n",
    "            score_df = score_df.merge(self.que, how='left', on='questions_id')\n",
    "        \n",
    "        return score_df\n",
    "    \n",
    "    \n",
    "    def convert_pro_dict(self, pro_dict: dict) -> (pd.DataFrame, pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Converts dictionary of professional data into desired form\n",
    "        :param pro_dict: dictionary of professional data\n",
    "        \"\"\"\n",
    "        # get DataFrame from dict\n",
    "        pro_df = pd.DataFrame.from_dict(pro_dict)\n",
    "        pros = pro_df['professionals_id'].values\n",
    "        \n",
    "        # create professional-tag tuples\n",
    "        tuples = []\n",
    "        for i, tags in enumerate(pro_df['professionals_subscribed_tags'].values):\n",
    "            pro = pros[i]\n",
    "            for tag in tags.split(' '):\n",
    "                tuples.append((pro, tag))\n",
    "        \n",
    "        # create DataFrame from tuples\n",
    "        pro_tags = pd.DataFrame(tuples, columns=['tag_users_user_id', 'tags_tag_name'])\n",
    "        pro_df.drop(columns='professionals_subscribed_tags', inplace=True)\n",
    "        \n",
    "        return pro_df, pro_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(content_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_dict = {\n",
    "    'questions_id': ['332a511f1569444485cf7a7a556a5e54'],\n",
    "    'questions_author_id': ['8f6f374ffd834d258ab69d376dd998f5'],\n",
    "    'questions_date_added': ['2016-04-26 11:14:26'],\n",
    "    'questions_title': ['Teacher   career   question'],\n",
    "    'questions_body': ['What  is  a  maths  teacher?   what  is  a  maths  teacher  useful? #college #professor #lecture'],\n",
    "    'questions_tags': ['college professor lecture']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_df, que_tags = predictor.convert_que_dict(que_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend the question to professionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>professionals_id</th>\n",
       "      <th>professionals_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>505fb5d32c1e41c5affe896328644832</td>\n",
       "      <td>0.858492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>fe151e90cc154d7da63b14fe6ed3c3e5</td>\n",
       "      <td>0.846544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>3ce003197d28478884ae0183a645d968</td>\n",
       "      <td>0.840861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>eab382099e2b4b03abdcbb4d85b5ec0d</td>\n",
       "      <td>0.828587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>d754969c1565445db381bb2d75273ee1</td>\n",
       "      <td>0.808249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>dcffe989be294141a523d71f3908c6bb</td>\n",
       "      <td>0.806587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>bf6edb3e76b94594a982c5776764cf75</td>\n",
       "      <td>0.797939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>aad8c9eaabf24305912b30a5d58137f6</td>\n",
       "      <td>0.795392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>9bf67236d34743768be67bd789dc618e</td>\n",
       "      <td>0.793254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>c2c6bf81c2e444ff834d98b58ab37687</td>\n",
       "      <td>0.792261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       questions_id                  professionals_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  505fb5d32c1e41c5affe896328644832   \n",
       "1  332a511f1569444485cf7a7a556a5e54  fe151e90cc154d7da63b14fe6ed3c3e5   \n",
       "2  332a511f1569444485cf7a7a556a5e54  3ce003197d28478884ae0183a645d968   \n",
       "3  332a511f1569444485cf7a7a556a5e54  eab382099e2b4b03abdcbb4d85b5ec0d   \n",
       "4  332a511f1569444485cf7a7a556a5e54  d754969c1565445db381bb2d75273ee1   \n",
       "5  332a511f1569444485cf7a7a556a5e54  dcffe989be294141a523d71f3908c6bb   \n",
       "6  332a511f1569444485cf7a7a556a5e54  bf6edb3e76b94594a982c5776764cf75   \n",
       "7  332a511f1569444485cf7a7a556a5e54  aad8c9eaabf24305912b30a5d58137f6   \n",
       "8  332a511f1569444485cf7a7a556a5e54  9bf67236d34743768be67bd789dc618e   \n",
       "9  332a511f1569444485cf7a7a556a5e54  c2c6bf81c2e444ff834d98b58ab37687   \n",
       "\n",
       "   professionals_score  \n",
       "0             0.858492  \n",
       "1             0.846544  \n",
       "2             0.840861  \n",
       "3             0.828587  \n",
       "4             0.808249  \n",
       "5             0.806587  \n",
       "6             0.797939  \n",
       "7             0.795392  \n",
       "8             0.793254  \n",
       "9             0.792261  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.find_pros_by_que(que_df, que_tags, expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find similar questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_questions_id</th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>f304f28d05ec473b8707ed88bb02b33e</td>\n",
       "      <td>0.904889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>f7d47936c73b49b2b480c7375a52acdc</td>\n",
       "      <td>0.903413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>f8294444f2fa4f78bc829f04ccbc06b7</td>\n",
       "      <td>0.873109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>6c98bbce49714e53a488a27e95ca4132</td>\n",
       "      <td>0.864905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>38f6b1a67866487b8707e389231ab4b7</td>\n",
       "      <td>0.864606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>f1a86d3c087c474b9457c9f10a94a21e</td>\n",
       "      <td>0.864024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>231dbfb6162b4518bb1789dd5a78fa6b</td>\n",
       "      <td>0.860059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>b38d19e10f404ff4867f160563283b63</td>\n",
       "      <td>0.856841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>bf41531f8a604ccdb7dd8ae9af6141af</td>\n",
       "      <td>0.851405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               initial_questions_id                      questions_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  332a511f1569444485cf7a7a556a5e54   \n",
       "1  332a511f1569444485cf7a7a556a5e54  f304f28d05ec473b8707ed88bb02b33e   \n",
       "2  332a511f1569444485cf7a7a556a5e54  f7d47936c73b49b2b480c7375a52acdc   \n",
       "3  332a511f1569444485cf7a7a556a5e54  f8294444f2fa4f78bc829f04ccbc06b7   \n",
       "4  332a511f1569444485cf7a7a556a5e54  6c98bbce49714e53a488a27e95ca4132   \n",
       "5  332a511f1569444485cf7a7a556a5e54  38f6b1a67866487b8707e389231ab4b7   \n",
       "6  332a511f1569444485cf7a7a556a5e54  f1a86d3c087c474b9457c9f10a94a21e   \n",
       "7  332a511f1569444485cf7a7a556a5e54  231dbfb6162b4518bb1789dd5a78fa6b   \n",
       "8  332a511f1569444485cf7a7a556a5e54  b38d19e10f404ff4867f160563283b63   \n",
       "9  332a511f1569444485cf7a7a556a5e54  bf41531f8a604ccdb7dd8ae9af6141af   \n",
       "\n",
       "   questions_score  \n",
       "0         1.000000  \n",
       "1         0.904889  \n",
       "2         0.903413  \n",
       "3         0.873109  \n",
       "4         0.864905  \n",
       "5         0.864606  \n",
       "6         0.864024  \n",
       "7         0.860059  \n",
       "8         0.856841  \n",
       "9         0.851405  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.find_ques_by_que(que_df, que_tags, expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.4 ms ± 3.28 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "predictor.find_ques_by_que(que_df, que_tags, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f predictor.find_ques_by_que predictor.find_ques_by_que(que_df, que_tags, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_dict = {\n",
    "    'professionals_id': ['44b2484ecd3642c6a47514f3876cf14a'],\n",
    "    'professionals_location': ['Cambridge, Massachusetts'],\n",
    "    'professionals_industry': ['Healthcare, Pharmaceuticals, Life Science'],\n",
    "    'professionals_headline': ['Scientist and Healthcare Entrepreneur'],\n",
    "    'professionals_date_joined': ['2012-01-25 20:40:43'],\n",
    "    'professionals_subscribed_tags': ['pharmaceutical-industry medicine healthcare-it biology science healthcare research']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_df, pro_tags = predictor.convert_pro_dict(pro_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend questions to the professional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_id</th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44b2484ecd3642c6a47514f3876cf14a</td>\n",
       "      <td>8aa85db69de34a238abf3808565f7ff0</td>\n",
       "      <td>0.915494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44b2484ecd3642c6a47514f3876cf14a</td>\n",
       "      <td>e71d0e419d5a4b40bb4d6bd4f30f3d43</td>\n",
       "      <td>0.915494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44b2484ecd3642c6a47514f3876cf14a</td>\n",
       "      <td>b8e51f4ab25e486f8c7fb9505d94fe31</td>\n",
       "      <td>0.907321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44b2484ecd3642c6a47514f3876cf14a</td>\n",
       "      <td>400c82f7a66f448ea590fd37ba82d881</td>\n",
       "      <td>0.892274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44b2484ecd3642c6a47514f3876cf14a</td>\n",
       "      <td>1426fd64bcb24c49ad89d54c681befd2</td>\n",
       "      <td>0.885919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44b2484ecd3642c6a47514f3876cf14a</td>\n",
       "      <td>a141f926dfff4fe0903ab23133ae3e00</td>\n",
       "      <td>0.882401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44b2484ecd3642c6a47514f3876cf14a</td>\n",
       "      <td>1ba041b8731841c4bf2b289a1ba38129</td>\n",
       "      <td>0.875935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44b2484ecd3642c6a47514f3876cf14a</td>\n",
       "      <td>c76814fcd9f5435796af8f886f642297</td>\n",
       "      <td>0.873863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44b2484ecd3642c6a47514f3876cf14a</td>\n",
       "      <td>2c46a965e09f455093ad21bf1cccb826</td>\n",
       "      <td>0.873863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44b2484ecd3642c6a47514f3876cf14a</td>\n",
       "      <td>5e165d6bad5e46dc80e5a004bb2760f7</td>\n",
       "      <td>0.872200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   professionals_id                      questions_id  \\\n",
       "0  44b2484ecd3642c6a47514f3876cf14a  8aa85db69de34a238abf3808565f7ff0   \n",
       "1  44b2484ecd3642c6a47514f3876cf14a  e71d0e419d5a4b40bb4d6bd4f30f3d43   \n",
       "2  44b2484ecd3642c6a47514f3876cf14a  b8e51f4ab25e486f8c7fb9505d94fe31   \n",
       "3  44b2484ecd3642c6a47514f3876cf14a  400c82f7a66f448ea590fd37ba82d881   \n",
       "4  44b2484ecd3642c6a47514f3876cf14a  1426fd64bcb24c49ad89d54c681befd2   \n",
       "5  44b2484ecd3642c6a47514f3876cf14a  a141f926dfff4fe0903ab23133ae3e00   \n",
       "6  44b2484ecd3642c6a47514f3876cf14a  1ba041b8731841c4bf2b289a1ba38129   \n",
       "7  44b2484ecd3642c6a47514f3876cf14a  c76814fcd9f5435796af8f886f642297   \n",
       "8  44b2484ecd3642c6a47514f3876cf14a  2c46a965e09f455093ad21bf1cccb826   \n",
       "9  44b2484ecd3642c6a47514f3876cf14a  5e165d6bad5e46dc80e5a004bb2760f7   \n",
       "\n",
       "   questions_score  \n",
       "0         0.915494  \n",
       "1         0.915494  \n",
       "2         0.907321  \n",
       "3         0.892274  \n",
       "4         0.885919  \n",
       "5         0.882401  \n",
       "6         0.875935  \n",
       "7         0.873863  \n",
       "8         0.873863  \n",
       "9         0.872200  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.find_ques_by_pro(pro_df, pro_tags, expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 ms ± 1.42 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "predictor.find_ques_by_pro(pro_df, pro_tags, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f predictor.find_ques_by_pro predictor.find_ques_by_pro(pro_df, pro_tags, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
